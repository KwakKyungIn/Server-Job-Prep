# 🔄 가상 메모리: 물리 메모리 크기의 극복 – 정책 (OSTEP Chapter 25)

이 장에서는 **물리 메모리보다 더 큰 가상 메모리**를 제공할 때, 어떤 페이지를 내보낼지 결정하는 **페이지 교체 정책(page replacement policy)** 을 다룬다.  
좋은 정책을 사용하면 디스크 접근 횟수를 줄여 성능을 크게 향상시킬 수 있다.

---

## ❓ 핵심 질문

> 물리 메모리에 빈 공간이 부족할 때, 어떤 페이지를 내보내야 가장 효율적일까?

---

## 🔍 상세 개념 정리

### 25.1 캐시 관리 관점으로 보기

#### 📂 페이지 캐시란?
- 메인 메모리는 가상 메모리 페이지들의 **캐시(cache)** 역할
- 목표: 디스크에서 읽어오는 **페이지 폴트(page fault)** 를 최소화

#### 📊 성능 지표: AMAT
| 용어 | 의미 |
|-----|------|
| AMAT | 평균 메모리 접근 시간 |
| TM | 메모리 접근 시간 (ex: 100ns) |
| TD | 디스크 접근 시간 (ex: 10ms) |
| PHit | 캐시 히트 확률 |
| PMiss | 캐시 미스 확률 (1 - PHit) |

**계산식:**  
```
AMAT = (PHit × TM) + (PMiss × TD)
```

➡ 디스크 접근 시간(TD)이 매우 크기 때문에, **조금만 미스율이 높아도 전체 성능이 급격히 저하됨**

---

### 25.2 최적 교체 정책 (Optimal Replacement Policy)

#### 🏅 가장 이상적인 정책
- **Belady's Algorithm (MIN)**  
- 지금부터 가장 나중에 다시 사용될 페이지를 내보냄

#### ❌ 단점
- 미래를 알아야 함 → 실제 구현 불가능
- 시뮬레이션 또는 기준 성능 측정용으로만 사용

---

### 25.3 간단한 정책: FIFO (First In, First Out)

#### 🔧 원리
- 가장 오래전에 메모리에 들어온 페이지를 내보냄

#### ✅ 장점
- 구현 간단

#### ❌ 단점
- 페이지가 얼마나 중요한지 고려하지 않음
- **Belady's Anomaly:** 캐시 크기를 늘려도 오히려 성능이 나빠질 수 있음

---

### 25.4 또 다른 간단한 정책: 무작위(Random)

#### 🔧 원리
- 아무 페이지나 무작위로 선택해 내보냄

#### ✅ 장점
- 구현 매우 간단
- 극단적 코너 케이스에서 FIFO보다 안정적

#### ❌ 단점
- 접근 이력을 전혀 고려하지 않음

---

### 25.5 과거 정보 기반 정책: LRU (Least Recently Used)

#### 🧠 원리
- 가장 오래 전에 사용된 페이지를 교체
- **지역성(Locality)의 원칙** 활용
  - 시간 지역성: 최근에 사용된 데이터가 다시 사용될 확률이 높음

#### ✅ 장점
- 대부분의 경우 최적 정책에 가까운 성능

#### ❌ 단점
- 정확하게 구현하려면 최근 사용 이력을 모두 추적해야 해서 비용 큼

---

### 25.6 다양한 워크로드에서의 성능 비교

| 워크로드 유형 | 특징 | 최적 정책 | FIFO/Random | LRU |
|---------------|------|------------|-------------|-----|
| 무작위 | 지역성 없음 | 성능 비슷 | 비슷 | 비슷 |
| 80:20 | 20% 페이지에서 80% 접근 | 최적 > LRU > Random/FIFO | 중간 | 우수 |
| 순환 반복 | 50개 페이지 반복 참조 | 최적 > Random | 매우 나쁨 | 나쁨 |

➡ LRU가 항상 최고의 성능을 내는 것은 아님. 워크로드에 따라 적절한 정책 선택 필요.

---

### 25.7 LRU의 구현 문제

#### 🚨 문제점
- 정확한 LRU 구현 시 매번 페이지 접근 시마다 시간 정보 업데이트 필요
- 대규모 시스템에서는 부담 큼

#### 🛠️ 개선 방법
- **Use Bit (Reference Bit):** 최근 접근 여부만 추적
- **시계 알고리즘(Clock Algorithm):**
  - 환형 리스트로 페이지 구성
  - Use Bit가 0인 페이지를 선택해 교체

---

### 25.8 LRU 근사 구현

| 알고리즘 | 설명 | 특징 |
|----------|------|------|
| Clock | Use Bit로 최근 사용 여부 추정 | LRU에 근접, 비용 낮음 |
| Second-Chance | Clock의 개선 버전 | 더 정확한 근사 |
| Enhanced Clock | Dirty Bit도 고려 | 디스크 쓰기 최소화 |

---

### 25.9 Dirty Page 고려

#### ⚙️ Dirty Bit란?
- 페이지가 **수정되었는지 여부**
- Dirty면 내보낼 때 디스크에 쓰기 필요 → 비용 큼

#### 🔧 교체 우선순위
1. 사용되지 않았고 깨끗한 페이지
2. 사용되지 않았지만 Dirty인 페이지
3. 최근 사용된 페이지

---

### 25.10 다른 VM 정책들

#### 📑 Page Selection (탑재 시점)
| 방법 | 설명 |
|------|------|
| Demand Paging | 필요할 때만 읽어옴 (기본) |
| Prefetching | 미리 읽어두기 (예: 코드 페이지 연속 탑재) |

#### 💾 쓰기 정책
| 방법 | 설명 |
|------|------|
| Write-through | 즉시 디스크에 기록 |
| Write-back | 모아서 한 번에 기록 (효율 ↑)

---

### 25.11 쓰래싱(Thrashing)

#### ⚠️ 문제
- 너무 자주 페이지 교체 발생 → 성능 급락

#### 🔧 해결책
- 일부 프로세스 강제 중지 (Working Set 관리)
- Linux: **OOM Killer** 로 과도한 메모리 사용 프로세스 종료

---

## ✅ 요약

페이지 교체 정책은 가상 메모리 성능을 좌우하는 핵심 요소다.  
지역성을 활용해 좋은 정책을 사용하면 페이지 폴트를 크게 줄일 수 있다.

| 정책 | 특징 | 장단점 |
|------|------|--------|
| Optimal | 가장 먼 미래 사용 페이지 제거 | 구현 불가, 성능 최고 |
| FIFO | 먼저 들어온 페이지 제거 | 단순하지만 비효율적 |
| Random | 무작위 제거 | 단순, 안정적이지만 최적 아님 |
| LRU | 가장 오래된 사용 페이지 제거 | 성능 우수, 구현 비용 높음 |
| Clock | LRU 근사 | 성능 좋고 비용 낮음 |

---

> 📚 출처: 『운영체제: 아주 쉬운 세 가지 이야기 (OSTEP)』
